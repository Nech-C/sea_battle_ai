[11]+  Stopped                 python bin/trainer.py --config config/ddqn_v0.1.1.toml --save_path models/
(pytorch) nech@LAPTOP-TDE1VV6L:~/projects/python_projects/sea_battle_ai$ python bin/trainer.py --config config/ddqn_v0.1.1.toml --save_path models/
episode: 0 | episode reward: -69.28 | training loss: N/A | ave steps: 1.08 | epsilon: 1.00
episode: 100 | episode reward: -178.33 | training loss: 0.16975 | ave steps: 160.2 | epsilon: 0.74
episode: 200 | episode reward: -85.29 | training loss: 0.11954 | ave steps: 175.13 | epsilon: 0.55
episode: 300 | episode reward: -63.22 | training loss: 0.12019 | ave steps: 176.9 | epsilon: 0.40
episode: 400 | episode reward: -36.35 | training loss: 0.08374 | ave steps: 127.51 | epsilon: 0.30
episode: 500 | episode reward: -4.32 | training loss: 0.07148 | ave steps: 73.94 | epsilon: 0.22
episode: 600 | episode reward: -0.27 | training loss: 0.11163 | ave steps: 60.87 | epsilon: 0.16
episode: 700 | episode reward: -0.22 | training loss: 0.06200 | ave steps: 50.37 | epsilon: 0.12
episode: 800 | episode reward: -3.35 | training loss: 0.07352 | ave steps: 41.58 | epsilon: 0.09
episode: 900 | episode reward: 0.72 | training loss: 0.07039 | ave steps: 40.9 | epsilon: 0.07
episode: 1000 | episode reward: 0.73 | training loss: 0.04901 | ave steps: 38.66 | epsilon: 0.05
episode: 1100 | episode reward: 0.74 | training loss: 0.06232 | ave steps: 38.29 | epsilon: 0.04
episode: 1200 | episode reward: 0.71 | training loss: 0.05640 | ave steps: 38.38 | epsilon: 0.03
episode: 1300 | episode reward: 0.67 | training loss: 0.05031 | ave steps: 36.58 | epsilon: 0.02
episode: 1400 | episode reward: 0.71 | training loss: 0.04903 | ave steps: 36.52 | epsilon: 0.01
episode: 1500 | episode reward: 0.68 | training loss: 0.05476 | ave steps: 35.76 | epsilon: 0.01
episode: 1600 | episode reward: -0.28 | training loss: 0.03339 | ave steps: 34.66 | epsilon: 0.01
episode: 1700 | episode reward: 0.75 | training loss: 0.03851 | ave steps: 35.11 | epsilon: 0.01
episode: 1800 | episode reward: 0.81 | training loss: 0.03066 | ave steps: 34.22 | epsilon: 0.01
episode: 1900 | episode reward: 0.74 | training loss: 0.02778 | ave steps: 33.49 | epsilon: 0.01
episode: 2000 | episode reward: 0.79 | training loss: 0.03797 | ave steps: 33.81 | epsilon: 0.01
episode: 2100 | episode reward: 0.79 | training loss: 0.01970 | ave steps: 32.95 | epsilon: 0.01
episode: 2200 | episode reward: 0.82 | training loss: 0.02388 | ave steps: 32.61 | epsilon: 0.01
episode: 2300 | episode reward: 0.81 | training loss: 0.02207 | ave steps: 33.21 | epsilon: 0.01
episode: 2400 | episode reward: 0.90 | training loss: 0.02943 | ave steps: 33.04 | epsilon: 0.01
episode: 2500 | episode reward: 0.64 | training loss: 0.02427 | ave steps: 30.93 | epsilon: 0.01
episode: 2600 | episode reward: 0.74 | training loss: 0.02022 | ave steps: 32.07 | epsilon: 0.01
episode: 2700 | episode reward: 0.72 | training loss: 0.01527 | ave steps: 31.59 | epsilon: 0.01
episode: 2800 | episode reward: 0.73 | training loss: 0.01633 | ave steps: 31.02 | epsilon: 0.01
episode: 2900 | episode reward: 0.85 | training loss: 0.01447 | ave steps: 31.7 | epsilon: 0.01
episode: 3000 | episode reward: 0.74 | training loss: 0.01670 | ave steps: 31.19 | epsilon: 0.01
episode: 3100 | episode reward: 0.78 | training loss: 0.01087 | ave steps: 31.57 | epsilon: 0.01
episode: 3200 | episode reward: 0.84 | training loss: 0.01135 | ave steps: 30.55 | epsilon: 0.01
episode: 3300 | episode reward: 0.82 | training loss: 0.01931 | ave steps: 30.91 | epsilon: 0.01
episode: 3400 | episode reward: 0.73 | training loss: 0.00828 | ave steps: 29.9 | epsilon: 0.01
episode: 3500 | episode reward: 0.78 | training loss: 0.01263 | ave steps: 30.36 | epsilon: 0.01
episode: 3600 | episode reward: 0.86 | training loss: 0.01104 | ave steps: 29.71 | epsilon: 0.01
episode: 3700 | episode reward: 0.77 | training loss: 0.01265 | ave steps: 29.27 | epsilon: 0.01
episode: 3800 | episode reward: 0.89 | training loss: 0.01520 | ave steps: 29.17 | epsilon: 0.01
episode: 3900 | episode reward: 0.75 | training loss: 0.01781 | ave steps: 30.12 | epsilon: 0.01
episode: 4000 | episode reward: 0.79 | training loss: 0.01320 | ave steps: 29.88 | epsilon: 0.01
episode: 4100 | episode reward: 0.81 | training loss: 0.00937 | ave steps: 29.52 | epsilon: 0.01
episode: 4200 | episode reward: 0.92 | training loss: 0.01069 | ave steps: 30.2 | epsilon: 0.01
episode: 4300 | episode reward: 0.72 | training loss: 0.01300 | ave steps: 30.24 | epsilon: 0.01
episode: 4400 | episode reward: 0.82 | training loss: 0.00968 | ave steps: 28.88 | epsilon: 0.01
episode: 4500 | episode reward: 0.68 | training loss: 0.01039 | ave steps: 29.62 | epsilon: 0.01
episode: 4600 | episode reward: 0.75 | training loss: 0.00919 | ave steps: 28.82 | epsilon: 0.01
episode: 4700 | episode reward: 0.92 | training loss: 0.00928 | ave steps: 28.44 | epsilon: 0.01
episode: 4800 | episode reward: 0.82 | training loss: 0.00965 | ave steps: 29.56 | epsilon: 0.01
episode: 4900 | episode reward: 0.79 | training loss: 0.00809 | ave steps: 28.95 | epsilon: 0.01
episode: 5000 | episode reward: 0.84 | training loss: 0.00921 | ave steps: 28.82 | epsilon: 0.01
episode: 5100 | episode reward: 0.82 | training loss: 0.00838 | ave steps: 28.49 | epsilon: 0.01
episode: 5200 | episode reward: 0.87 | training loss: 0.00813 | ave steps: 29.2 | epsilon: 0.01
episode: 5300 | episode reward: 0.88 | training loss: 0.00747 | ave steps: 28.61 | epsilon: 0.01
episode: 5400 | episode reward: 0.88 | training loss: 0.00795 | ave steps: 28.16 | epsilon: 0.01
episode: 5500 | episode reward: 0.89 | training loss: 0.00939 | ave steps: 28.62 | epsilon: 0.01
episode: 5600 | episode reward: 0.77 | training loss: 0.00696 | ave steps: 28.24 | epsilon: 0.01
episode: 5700 | episode reward: 0.77 | training loss: 0.00723 | ave steps: 30.67 | epsilon: 0.01
episode: 5800 | episode reward: 0.94 | training loss: 0.00866 | ave steps: 28.67 | epsilon: 0.01
episode: 5900 | episode reward: 0.76 | training loss: 0.00845 | ave steps: 29.41 | epsilon: 0.01
episode: 6000 | episode reward: 0.80 | training loss: 0.00713 | ave steps: 28.34 | epsilon: 0.01
episode: 6100 | episode reward: 0.78 | training loss: 0.00947 | ave steps: 29.32 | epsilon: 0.01
episode: 6200 | episode reward: 0.76 | training loss: 0.00898 | ave steps: 27.34 | epsilon: 0.01
episode: 6300 | episode reward: 0.91 | training loss: 0.00739 | ave steps: 29.67 | epsilon: 0.01
episode: 6400 | episode reward: -0.26 | training loss: 0.00998 | ave steps: 27.76 | epsilon: 0.01
episode: 6500 | episode reward: 0.90 | training loss: 0.00793 | ave steps: 28.49 | epsilon: 0.01
episode: 6600 | episode reward: 0.81 | training loss: 0.00811 | ave steps: 26.52 | epsilon: 0.01
episode: 6700 | episode reward: 0.84 | training loss: 0.00576 | ave steps: 27.22 | epsilon: 0.01
episode: 6800 | episode reward: 0.79 | training loss: 0.00703 | ave steps: 26.48 | epsilon: 0.01
episode: 6900 | episode reward: 0.72 | training loss: 0.00652 | ave steps: 29.17 | epsilon: 0.01
episode: 7000 | episode reward: 0.79 | training loss: 0.00730 | ave steps: 27.8 | epsilon: 0.01
episode: 7100 | episode reward: 0.88 | training loss: 0.00717 | ave steps: 27.7 | epsilon: 0.01
episode: 7200 | episode reward: 0.83 | training loss: 0.00759 | ave steps: 27.32 | epsilon: 0.01
episode: 7300 | episode reward: -0.26 | training loss: 0.00784 | ave steps: 26.81 | epsilon: 0.01
episode: 7400 | episode reward: 0.83 | training loss: 0.00706 | ave steps: 26.96 | epsilon: 0.01
episode: 7500 | episode reward: 0.83 | training loss: 0.00700 | ave steps: 27.4 | epsilon: 0.01
episode: 7600 | episode reward: 0.92 | training loss: 0.00669 | ave steps: 27.4 | epsilon: 0.01
episode: 7700 | episode reward: 0.93 | training loss: 0.00606 | ave steps: 28.01 | epsilon: 0.01
episode: 7800 | episode reward: 0.74 | training loss: 0.00594 | ave steps: 26.28 | epsilon: 0.01
episode: 7900 | episode reward: 0.87 | training loss: 0.00701 | ave steps: 26.68 | epsilon: 0.01
episode: 8000 | episode reward: 0.89 | training loss: 0.00726 | ave steps: 27.49 | epsilon: 0.01
episode: 8100 | episode reward: 0.75 | training loss: 0.00717 | ave steps: 28.09 | epsilon: 0.01
episode: 8200 | episode reward: 0.86 | training loss: 0.00683 | ave steps: 27.56 | epsilon: 0.01
episode: 8300 | episode reward: -0.18 | training loss: 0.00695 | ave steps: 26.9 | epsilon: 0.01
episode: 8400 | episode reward: 0.94 | training loss: 0.00756 | ave steps: 25.79 | epsilon: 0.01
episode: 8500 | episode reward: 0.69 | training loss: 0.00692 | ave steps: 27.65 | epsilon: 0.01
episode: 8600 | episode reward: 0.85 | training loss: 0.00768 | ave steps: 27.06 | epsilon: 0.01
episode: 8700 | episode reward: 0.85 | training loss: 0.00607 | ave steps: 26.46 | epsilon: 0.01
episode: 8800 | episode reward: 0.82 | training loss: 0.00623 | ave steps: 26.09 | epsilon: 0.01
episode: 8900 | episode reward: 0.87 | training loss: 0.00563 | ave steps: 26.26 | epsilon: 0.01
episode: 9000 | episode reward: 0.77 | training loss: 0.00571 | ave steps: 26.2 | epsilon: 0.01
episode: 9100 | episode reward: 0.82 | training loss: 0.00459 | ave steps: 26.22 | epsilon: 0.01
episode: 9200 | episode reward: 0.81 | training loss: 0.00524 | ave steps: 25.76 | epsilon: 0.01
episode: 9300 | episode reward: 0.88 | training loss: 0.00485 | ave steps: 26.06 | epsilon: 0.01
episode: 9400 | episode reward: 0.82 | training loss: 0.00583 | ave steps: 26.0 | epsilon: 0.01
episode: 9500 | episode reward: 0.80 | training loss: 0.00620 | ave steps: 26.04 | epsilon: 0.01
episode: 9600 | episode reward: -0.22 | training loss: 0.00545 | ave steps: 26.17 | epsilon: 0.01
episode: 9700 | episode reward: 0.92 | training loss: 0.00572 | ave steps: 24.88 | epsilon: 0.01
episode: 9800 | episode reward: 0.86 | training loss: 0.00569 | ave steps: 26.43 | epsilon: 0.01
episode: 9900 | episode reward: 0.75 | training loss: 0.00712 | ave steps: 25.98 | epsilon: 0.01
episode: 10000 | episode reward: 0.85 | training loss: 0.00461 | ave steps: 26.19 | epsilon: 0.01
episode: 10100 | episode reward: 0.93 | training loss: 0.00574 | ave steps: 26.19 | epsilon: 0.01
episode: 10200 | episode reward: 0.83 | training loss: 0.00516 | ave steps: 24.79 | epsilon: 0.01
episode: 10300 | episode reward: 0.87 | training loss: 0.00451 | ave steps: 26.04 | epsilon: 0.01
episode: 10400 | episode reward: 0.86 | training loss: 0.00493 | ave steps: 25.21 | epsilon: 0.01
episode: 10500 | episode reward: 0.80 | training loss: 0.00584 | ave steps: 25.8 | epsilon: 0.01
episode: 10600 | episode reward: 0.76 | training loss: 0.00588 | ave steps: 25.44 | epsilon: 0.01
episode: 10700 | episode reward: -0.18 | training loss: 0.00533 | ave steps: 24.92 | epsilon: 0.01
episode: 10800 | episode reward: -0.25 | training loss: 0.00521 | ave steps: 25.43 | epsilon: 0.01
episode: 10900 | episode reward: 0.77 | training loss: 0.00487 | ave steps: 25.44 | epsilon: 0.01
episode: 11000 | episode reward: 0.90 | training loss: 0.00615 | ave steps: 26.24 | epsilon: 0.01
episode: 11100 | episode reward: 0.93 | training loss: 0.00587 | ave steps: 26.63 | epsilon: 0.01
episode: 11200 | episode reward: 0.87 | training loss: 0.00474 | ave steps: 26.31 | epsilon: 0.01
episode: 11300 | episode reward: 0.79 | training loss: 0.00530 | ave steps: 25.83 | epsilon: 0.01
episode: 11400 | episode reward: 0.85 | training loss: 0.00596 | ave steps: 26.63 | epsilon: 0.01
episode: 11500 | episode reward: 0.75 | training loss: 0.00554 | ave steps: 25.65 | epsilon: 0.01
episode: 11600 | episode reward: -0.16 | training loss: 0.00579 | ave steps: 25.55 | epsilon: 0.01
episode: 11700 | episode reward: 0.83 | training loss: 0.00557 | ave steps: 26.3 | epsilon: 0.01
episode: 11800 | episode reward: 0.84 | training loss: 0.00550 | ave steps: 25.49 | epsilon: 0.01
episode: 11900 | episode reward: -1.15 | training loss: 0.00528 | ave steps: 26.39 | epsilon: 0.01
episode: 12000 | episode reward: 0.93 | training loss: 0.00529 | ave steps: 26.32 | epsilon: 0.01
episode: 12100 | episode reward: 0.76 | training loss: 0.00550 | ave steps: 26.59 | epsilon: 0.01
episode: 12200 | episode reward: 0.86 | training loss: 0.00453 | ave steps: 27.97 | epsilon: 0.01
episode: 12300 | episode reward: 0.77 | training loss: 0.00481 | ave steps: 26.01 | epsilon: 0.01
episode: 12400 | episode reward: 0.86 | training loss: 0.00515 | ave steps: 26.93 | epsilon: 0.01
episode: 12500 | episode reward: 0.92 | training loss: 0.00496 | ave steps: 26.62 | epsilon: 0.01
episode: 12600 | episode reward: 0.79 | training loss: 0.00638 | ave steps: 26.51 | epsilon: 0.01
episode: 12700 | episode reward: 0.73 | training loss: 0.00444 | ave steps: 26.15 | epsilon: 0.01
episode: 12800 | episode reward: 0.85 | training loss: 0.00523 | ave steps: 27.1 | epsilon: 0.01
episode: 12900 | episode reward: 0.85 | training loss: 0.00383 | ave steps: 27.88 | epsilon: 0.01
episode: 13000 | episode reward: -0.20 | training loss: 0.00514 | ave steps: 26.03 | epsilon: 0.01
episode: 13100 | episode reward: 0.76 | training loss: 0.00406 | ave steps: 27.36 | epsilon: 0.01
episode: 13200 | episode reward: 0.83 | training loss: 0.00435 | ave steps: 26.55 | epsilon: 0.01
episode: 13300 | episode reward: 0.80 | training loss: 0.00411 | ave steps: 27.51 | epsilon: 0.01
episode: 13400 | episode reward: 0.92 | training loss: 0.00400 | ave steps: 27.67 | epsilon: 0.01
episode: 13500 | episode reward: 0.84 | training loss: 0.00458 | ave steps: 27.96 | epsilon: 0.01
episode: 13600 | episode reward: 0.93 | training loss: 0.00390 | ave steps: 26.92 | epsilon: 0.01
episode: 13700 | episode reward: 0.84 | training loss: 0.00400 | ave steps: 26.57 | epsilon: 0.01
episode: 13800 | episode reward: 0.87 | training loss: 0.00455 | ave steps: 26.55 | epsilon: 0.01
episode: 13900 | episode reward: 0.74 | training loss: 0.00332 | ave steps: 26.54 | epsilon: 0.01
episode: 14000 | episode reward: -0.24 | training loss: 0.00424 | ave steps: 27.84 | epsilon: 0.01
episode: 14100 | episode reward: 0.85 | training loss: 0.00376 | ave steps: 27.11 | epsilon: 0.01
episode: 14200 | episode reward: 0.93 | training loss: 0.00318 | ave steps: 27.64 | epsilon: 0.01
episode: 14300 | episode reward: 0.81 | training loss: 0.00363 | ave steps: 26.44 | epsilon: 0.01
episode: 14400 | episode reward: 0.72 | training loss: 0.00363 | ave steps: 27.82 | epsilon: 0.01
episode: 14500 | episode reward: 0.80 | training loss: 0.00340 | ave steps: 27.02 | epsilon: 0.01
episode: 14600 | episode reward: 0.78 | training loss: 0.00290 | ave steps: 27.84 | epsilon: 0.01
episode: 14700 | episode reward: -0.15 | training loss: 0.00344 | ave steps: 28.58 | epsilon: 0.01
episode: 14800 | episode reward: 0.79 | training loss: 0.00325 | ave steps: 27.62 | epsilon: 0.01
episode: 14900 | episode reward: 0.78 | training loss: 0.00318 | ave steps: 26.99 | epsilon: 0.01
[11]+  Killed                  python bin/trainer.py --config config/ddqn_v0.1.1.toml --save_path models/