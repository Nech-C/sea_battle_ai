model_name = "ddqn_v0.1.7.pth"

[architecture]
layer_sizes = [147, 512, 64, 49]

[hyperparameters]
learning_rate = 0.0002
gamma = 0.99
epsilon_start = 1.0
epsilon_end = 0.01
epsilon_decay = 0.9986
target_update_freq = 800
memory_capacity = 50000
batch_size = 512
tau = 0.1
dropout1 = 0
droupout2 = 0


[training]
num_episodes = 20000
save_interval = 500
invalid_action_limit = 20

[rewards]
hit = 0.01
sunk = 0.01
miss = -0.02
other = -1
done = 1

[info]
# add dropout layer
# try new rewards